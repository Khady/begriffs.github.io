<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Begriffs.com blog</title>
    <link href="http://begriffs.com/atom.xml" rel="self" />
    <link href="http://begriffs.com" />
    <id>http://begriffs.com/atom.xml</id>
    <author>
        <name>Joe Nelson</name>
        <email>cred+blog@begriffs.com</email>
    </author>
    <updated>2015-09-04T00:00:00Z</updated>
    <entry>
    <title>FP Graph Algorithms</title>
    <link href="http://begriffs.com/posts/2015-09-04-pure-functional-graphs.html" />
    <id>http://begriffs.com/posts/2015-09-04-pure-functional-graphs.html</id>
    <published>2015-09-04T00:00:00Z</published>
    <updated>2015-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>FP Graph Algorithms</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">September  4, 2015</h5>
</div>

<div class="content">
  <p>Manipulating graphs has traditionally been seen as a place where imperative programming reigns supreme. <a href="http://jelv.is/">Tikhon Jelvis</a> begs to differ, and shows a trick where graph traversal can be expressed by a form of pattern matching. After explaining the approach he simulates how it works on a sample graph.</p>
<video poster="https://i.vimeocdn.com/video/533642391.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/138339869.hd.mp4?s=e29a8ef4fa7370f4b2e13b753e4e9fd9" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li>Traditionally graph algorithms are seen as one of the things that are really hard in functional programming</li>
<li>To some extent it is because the graph algorithms and representations you’ve learned have a very imperative bent</li>
<li>One insight into making a graph algorithm functional is to find a way to use pattern matching on a graph structure
<ul>
<li>What does this even mean?</li>
<li>Start with what we already know: pattern matching is easy on lists or trees</li>
<li>Translates to any algebraic data type really</li>
<li>But there is no algebraic data type for graphs</li>
<li>Graphs are not inductive — there is more than one way to build them up or take them apart</li>
</ul></li>
<li>But we can pretend! We can treat graphs as if they were inductive</li>
<li>So how do we break a graph apart in a pattern match?
<ul>
<li>We’ll use a a “view”</li>
<li><code>match :: Node -&gt; Graph -&gt; Maybe View</code></li>
</ul></li>
<li>Depth first search
<ul>
<li>We don’t update flags on nodes to say which we have visited</li>
<li>Our recursion just happens on a subgraph that does not re-visit nodes</li>
<li>Example of the operation on a specific graph</li>
</ul></li>
<li>You can find the implementation in the <a href="http://hackage.haskell.org/package/fgl">Functional Graph Library</a></li>
<li>Slides for this talk are available <a href="http://jelv.is/talks/inductive-graphs-at-wagon/#/sec-title-slide">here</a></li>
<li>For an example of generating mazes using functional programming, check out this <a href="http://jelv.is/blog/Generating-Mazes-with-Inductive-Graphs/">blog post</a></li>
<li>Q&amp;A</li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Applicatives in Math vs Code</title>
    <link href="http://begriffs.com/posts/2015-08-30-applicative-functors.html" />
    <id>http://begriffs.com/posts/2015-08-30-applicative-functors.html</id>
    <published>2015-08-30T00:00:00Z</published>
    <updated>2015-08-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>Applicatives in Math vs Code</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">August 30, 2015</h5>
</div>

<div class="content">
  <p><a href="https://twitter.com/deland">Matt DeLand</a> contrasts the mathematical and software ways of thinking about applicative functors. Coding in Haskell and reasoning in category theory are two routes that lead to the same concept, and Matt shows how someone in either discipline would arrive at applicatives. He provides examples of applicative functors and – interestingly – a counterexample.</p>
<video poster="https://i.vimeocdn.com/video/532751406.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/137713584.hd.mp4?s=d6620b136f72d5d0c7ded459883b4096" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li>Haskell as category theory
<ul>
<li>The category Hask of types and functions between them</li>
<li>This is called the “idealized” Haskell category because it ignores possibilities like functions blowing up (exceptions etc)</li>
<li>Arrows in Hask agree only if they agree on all values</li>
<li>Some extra structure: for any type T there is an arrow from T to unit <code>()</code>, i.e. unit is a terminal object</li>
<li>Values of a type T can be identified as arrows from unit to <code>a</code>. Each arrow picks out an element as it were</li>
<li>The category is also monoidal</li>
<li>“Part of category theory is giving long names to ideas with no content. We’re going to follow in a long tradition!”</li>
<li>How functors work</li>
<li>Examples are Maybe, [], ( Int, _ )</li>
<li>One counter-example is <code>a -&gt; (a -&gt; Int)</code></li>
</ul></li>
<li>How might a category theorist come to the notion of applicative functor?
<ul>
<li>Hask has some structure beyond the bare requirements of being a category</li>
<li>It has a final object (unit) monoidal pairing.</li>
<li>What functors behave nicely with respect to that relationship?</li>
<li>In category land they would be called “lax monoidal” functors</li>
</ul></li>
<li>The programmer’s take
<ul>
<li>What applicative functors provide</li>
<li>The standard typeclass definition is a bit overspecified (axiomatically the two standard properties imply the third)</li>
</ul></li>
<li>Proof that category theory version implies programmer version</li>
<li>Proof that programmer’s version implies category theory version</li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Dev and Deploy Haskell on Docker</title>
    <link href="http://begriffs.com/posts/2015-08-11-dev-deploy-haskell-docker.html" />
    <id>http://begriffs.com/posts/2015-08-11-dev-deploy-haskell-docker.html</id>
    <published>2015-08-11T00:00:00Z</published>
    <updated>2015-08-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>Dev and Deploy Haskell on Docker</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">August 11, 2015</h5>
</div>

<div class="content">
  <p><a href="http://www.christopherbiscardi.com/">Christopher Biscardi</a> shares his Docker wisdom, showing how to package the whole Haskell dev environment inside a container and how to optimize it for production release.</p>
<video poster="https://i.vimeocdn.com/video/530093762.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/135823847.hd.mp4?s=e7db2f1e096004d428858b69a3515415" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li>How do we build Haskell code locally?</li>
<li>Docker is one answer</li>
<li>In the Dockerfile copy your source code into the image, then cabal update and cabal install</li>
<li>This works but it is naive
<ul>
<li>Changing any file causes you to rebuild everything (the whole cabal sandbox!)</li>
</ul></li>
<li>So we could try to optimize the Dockerfile
<ul>
<li>Have to determine the individual pieces and where they will end up and how long that should take</li>
</ul></li>
<li>Heavily optimizing Dockerfiles takes work, and it’s more fun to build your application than burn time tweaking the Dockerfile</li>
<li>A better solution is to use Docker as your development environment
<ul>
<li>Clone your project</li>
<li>Docker run an interactive tty</li>
<li>Mount the directory</li>
<li>At that point you’re in the container and can install deps, build the sandbox, etc</li>
<li>Container changes are persisted to a volume so you can kill it and resume work later</li>
</ul></li>
<li>This way you don’t need Haskell installed in the host system at all</li>
<li>Easy to switch GHC version between projects</li>
<li>How do we ship the dev work to production?
<ul>
<li>Building a new Docker image containing the binary built in dev results in shared library errors</li>
<li>Solution: build a static binary</li>
<li>Works, and plays well with Circle CI etc</li>
</ul></li>
<li>The production image unfortunately can be rather big, like 150mb
<ul>
<li>Solution: compile GHC with MUSL</li>
<li>…or if you want to cheat, just use the <a href="https://github.com/nilcons/ghc-musl">nilcons/ghc-musl</a> image</li>
<li>Chris’ production image (based on Alpine) shrank down to 36mb</li>
</ul></li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Nix ±Cabal</title>
    <link href="http://begriffs.com/posts/2015-08-07-nix-plus-minus-cabal.html" />
    <id>http://begriffs.com/posts/2015-08-07-nix-plus-minus-cabal.html</id>
    <published>2015-08-07T00:00:00Z</published>
    <updated>2015-08-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>Nix ±Cabal</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">August  7, 2015</h5>
</div>

<div class="content">
  <p><a href="http://earldouglas.com/">James Earl Douglas</a>, Technical Lead at the Wikimedia Foundation, shares his recent experience using Nix to manage system state. He discusses installing it in Ubuntu, using Nix to install other packages, and finally how it interacts with GHC and Cabal.</p>
<video poster="https://i.vimeocdn.com/video/529705750.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/135615305.hd.mp4?s=bcc3febf8794750db8afb64f97991846" type="video/mp4">
</video>
<p>See the slides <a href="http://earldouglas.com/presentations/nix-maybe-cabal/slides.html#(1)">here</a>.</p>
<h3 id="summary">Summary</h3>
<ul>
<li>A newcomer’s perspective on nix</li>
<li>Cabal can be difficult to use and nix helps alleviate that pain</li>
<li>Nix is purely functional
<ul>
<li>Packages never change</li>
<li>Helps resolve version conflicts of tools (like ghc) and libraries (like base)</li>
</ul></li>
<li>Each package is stored in a unique, read-only directory</li>
<li>Packages have a hash that forever identify both them and their dependencies</li>
<li>Within NixOS itself
<ul>
<li>Everything lives in a nonstandard place, even bash</li>
<li>No more “hash-bang-bin-bash” — use the <code>env</code> command</li>
</ul></li>
<li>Getting started on Ubuntu
<ul>
<li>Install by curling and running a shell script</li>
<li>Installing ghc and cabal from scratch with the nix-env command</li>
<li>Making specific packages visible with <code>nix-shell</code></li>
</ul></li>
<li>Examples of Nix configuration and expressions</li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Haskell Source Navigation</title>
    <link href="http://begriffs.com/posts/2015-07-27-haskell-source-navigation.html" />
    <id>http://begriffs.com/posts/2015-07-27-haskell-source-navigation.html</id>
    <published>2015-07-27T00:00:00Z</published>
    <updated>2015-07-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>Haskell Source Navigation</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">July 27, 2015</h5>
</div>

<div class="content">
  <p>In this video I demonstrate the use of command-line tools to interactively explore Haskell source code. The tools provide a fluid development experience but can be tricky to configure. This talk covers their use, configuration, and integration with an editor.</p>
<video poster="https://i.vimeocdn.com/video/528283298.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/134634569.hd.mp4?s=bca20c829e3a57bc54fd9f6b90210439" type="video/mp4">
</video>
<p><a class="embedly-card" href="http://www.slideshare.net/begriffs/haskell-code-tools">Haskell Source Navigation</a></p>
<h3 id="summary">Summary</h3>
<ul>
<li>Types provide more than just safety</li>
<li>Haskell has enough structure to support sophisticated tools
<ul>
<li>Jump to symbol definitions</li>
<li>Find all uses of functions</li>
<li>Get (good) linting suggestions</li>
<li>Interactive error checking</li>
<li>Finding docs by type or name</li>
<li>Autocompletion from dependencies</li>
<li>Code formatting</li>
</ul></li>
<li>Getting into the tools themselves, below the editor layer
<ul>
<li>hasktags</li>
<li>codex</li>
<li>hscope</li>
<li>hoogle</li>
<li>hoobuddy</li>
<li>Alfred shortcuts</li>
<li>ghc-mod</li>
<li>hlint</li>
<li>stylish-haskell</li>
<li>hindent</li>
</ul></li>
<li>Putting them together into a <a href="https://github.com/begriffs/haskell-vim-now">vim config</a></li>
</ul>
<script async src="//cdn.embedly.com/widgets/platform.js" charset="UTF-8"></script>
</div>
]]></summary>
</entry>
<entry>
    <title>The Essence of FRP</title>
    <link href="http://begriffs.com/posts/2015-07-22-essence-of-frp.html" />
    <id>http://begriffs.com/posts/2015-07-22-essence-of-frp.html</id>
    <published>2015-07-22T00:00:00Z</published>
    <updated>2015-07-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>The Essence of FRP</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">July 22, 2015</h5>
</div>

<div class="content">
  <p><a href="http://conal.net/blog/">Conal Elliott</a> proposed functional reactive programming twenty years ago with a clear denotational semantics. Over time the idea gained popularity but the original conception became blurred. In this video Conal explains FRP’s original formulation and its benefits.</p>
<video poster="https://i.vimeocdn.com/video/527644244.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/134223272.hd.mp4?s=970e3b0ce3453570227910fa68302737" type="video/mp4">
</video>
<p>Slides are available <a href="https://github.com/conal/talk-2015-essence-and-origins-of-frp">here</a>.</p>
<h3 id="summary">Summary</h3>
<ul>
<li>FRP is is receiving more interest now but has become misunderstood
<ul>
<li>The notion of FRP was very precisely defined 20 years ago</li>
<li>It allows us to reason precisely and simply</li>
<li>The term has been used incorrectly to describe systems like Elm, Bacon, and Reactive Extensions</li>
</ul></li>
<li>The true essence is shaped by two fundamental ideas
<ul>
<li>Continuous time (its non-strictness enables modularity, see Why Functional Programming Matters)</li>
<li>Simple denotation allows dependable reasoning</li>
</ul></li>
<li>Reasons for continuous rather than discrete</li>
<li>Approximations compose badly, so postpone until the end</li>
<li>We don’t need to have an opinion about what FRP means! Use math.
<ul>
<li>There is one datatype: <code>Behavior a</code></li>
<li>Then a meaning, or <code>m</code>, of a behavior maps a behavior to a function on time. <code>m :: Behavior a -&gt; (Reals -&gt; a)</code></li>
<li>The original formulation of FRP from 1994 lacked the modern vocabulary.</li>
</ul></li>
<li>The modernized formulation
<ul>
<li>Behaviors are Functors, Applicatives, and Monoids</li>
<li>If <code>a</code> is a Monoid then so is <code>Event a</code></li>
<li>Comparing the original semantics of Behavior with typeclass instances</li>
<li>Event is just Behavior composed with the list constructor</li>
</ul></li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>The Design of Purescript Halogen</title>
    <link href="http://begriffs.com/posts/2015-07-10-design-of-purescript-halogen.html" />
    <id>http://begriffs.com/posts/2015-07-10-design-of-purescript-halogen.html</id>
    <published>2015-07-10T00:00:00Z</published>
    <updated>2015-07-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>The Design of Purescript Halogen</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">July 10, 2015</h5>
</div>

<div class="content">
  <p><a href="http://functorial.com/">Phil Freeman</a>, the author of Purescript, explains the design of <a href="https://github.com/slamdata/purescript-halogen">Halogen</a>, a declarative, type-safe UI library.</p>
<video poster="https://i.vimeocdn.com/video/525705269.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/132859139.hd.mp4?s=5cecdf40c05e5562be23e38fdc97021a" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li>Purescript-halogen
<ul>
<li>a toolkit for building reactive web apps in purescript</li>
<li>built on signal functions and a virtual dom</li>
</ul></li>
<li>Signals are values which change over time
<ul>
<li>they are functors and applicatives</li>
</ul></li>
<li>The “stateful” combinator creates a new signal from an old one, adding a stateful input. It is called foldp in Elm or stepper
<ul>
<li>for example if a signal wraps up a monoid then you can define a combine function which produces a new signal of the latest mconcat’d values</li>
</ul></li>
<li>Halogen provides a DOM templating DSL which builds a type <code>HTML</code></li>
<li>A user interface can be considered a <code>Signal HTML</code>
<ul>
<li>when the signal changes, push the diffs to the DOM</li>
</ul></li>
<li>Halogen goes beyond such simple Signals to Signal functions, i.e. <code>type UI input = Signal input -&gt; Signal (HTML input)</code></li>
<li>Signal functions do have a mathematical denotation</li>
<li>The concrete representation of signal functions in Halogen</li>
<li>Signal functions also have Functor and Applicative instances (slides have a diagram)</li>
<li>But signal functions have some additional type class instances: Profunctor, Strong, Choice</li>
<li>Signal functions also have a stateful combinator</li>
<li>Explanation of the merge combinator</li>
<li>Putting this all together, the signal functions and combinators combine to create graphs of data flow</li>
<li>In Halogen you get a lot of composability for free, which works well when defining web components</li>
<li>Components actually have a type interface: <code>type Component m i o   = SF i (HTML (m o))</code></li>
<li>Mixins become easy inside the graph of pure functions
<ul>
<li>Undo/redo</li>
<li>Routing</li>
<li>Sitemap / breadcrumbs</li>
</ul></li>
<li>How to handle
<ul>
<li>Ajax</li>
<li>External input</li>
<li>Third-party code</li>
<li>Canvas, SVG, WebGL</li>
</ul></li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>From Haskell to Hardware</title>
    <link href="http://begriffs.com/posts/2015-06-28-haskell-to-hardware.html" />
    <id>http://begriffs.com/posts/2015-06-28-haskell-to-hardware.html</id>
    <published>2015-06-28T00:00:00Z</published>
    <updated>2015-06-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>From Haskell to Hardware</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">June 28, 2015</h5>
</div>

<div class="content">
  <p><a href="http://conal.net/blog/">Conal Elliott</a> uses a reformulated interpretation of lambda calculus to transform Haskell programs into highly parallelized circuits. He gave this talk at <a href="http://bayhac.org/">Bayhac 2015</a>. His approach allows him to structure parallel programming using a richer set of data structures than the usual array-based thinking. (<a href="https://github.com/conal/talk-2015-haskell-to-hardware">slides</a>)</p>
<video poster="https://i.vimeocdn.com/video/524462436.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/131952196.hd.mp4?s=7038f182348196c3cc0e87bf7d4170bf" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li>We turn Haskell into a tree structure of operations and thence to Verilog</li>
<li>The same code generates different circuits depending on which types we specify for the polymorphism</li>
<li>Guiding intuition: overloading lambda and application by using type classes</li>
<li>The technical steps
<ul>
<li>Compile Haskell to the Core language</li>
<li>Monomorphize</li>
<li>Convert to abstract vocabulary</li>
<li>Interpret as circuits</li>
<li>Synthesize with existing HDL machinery</li>
</ul></li>
<li>It is within the abstract vocabulary that lambdas are overloaded</li>
<li>The abstract form is not combinatory logic, it is cartesian closed categories</li>
<li>The idea comes from J. Lambek who showed that there are interpretations of the lambda calculus other than the standard one of functions</li>
<li>Examples of Haskell programs and the circuits they generate</li>
<li>Going beyond arrays for parallel programming
<ul>
<li>uniform pairs</li>
<li>vectors of known length</li>
<li>depth-typed trees, bottom-up and top-down</li>
</ul></li>
<li>Implementing dot products and matrix multiplication</li>
<li>Generalizing them by relaxing type constraints
<ul>
<li>Generates more parallelism, log depth trees rather than linear depth</li>
</ul></li>
<li>Implementing bitonic sort
<ul>
<li>Generates fantastically complicated circuits but ones which are certainly correct</li>
</ul></li>
<li>Implementing parallel scan</li>
<li>Implementing polynomial evaluation in log time</li>
<li>Combinational circuits have no state, but we can generate stateful ones too
<ul>
<li>Using a data type that models a Mealy machine</li>
</ul></li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Stack, the Haskell Build Tool</title>
    <link href="http://begriffs.com/posts/2015-06-22-haskell-stack-build-tool.html" />
    <id>http://begriffs.com/posts/2015-06-22-haskell-stack-build-tool.html</id>
    <published>2015-06-22T00:00:00Z</published>
    <updated>2015-06-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>Stack, the Haskell Build Tool</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">June 22, 2015</h5>
</div>

<div class="content">
  <p><a href="https://unknownparallel.wordpress.com/">Dan Burton</a> gave this talk at <a href="http://bayhac.org/">Bayhac 2015</a>. In it he introduces Stack, a candidate replacement for Cabal. The tool provides an easy one line command to install Haskell packages. It also installs any missing tools onto the system (GHC, Cabal, and libraries like alex, happy and cpphs). By default it uses the curated Stackage long-term support databases to choose packages known to build and coexist together. Finally it reuses previously installed packages whenever possible to avoid unnecessary recompilation.</p>
<video poster="https://i.vimeocdn.com/video/523723567.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/131463587.hd.mp4?s=027fe40cde79f1e2b7ce47e6eed66a06" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li><a href="https://github.com/commercialhaskell/stack">Stack</a> is a build tool for developers, currently in beta
<ul>
<li>The spiritual successor to stackage-cli</li>
<li>It can install packages and also prereqs like GHC itself</li>
</ul></li>
<li>Stack builds on top of <a href="https://www.stackage.org/lts">LTS Haskell</a> which is a curated set of packages from package
<ul>
<li>alleviates dependency hell</li>
<li>upgrading minor version of LTS implies upgrading only up to minor versions of each package</li>
<li>To get your package added to stackage, follow these <a href="http://www.stackage.org/authors">instructions</a></li>
</ul></li>
<li>Each project needs a stack.yaml</li>
</ul>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml">   <span class="co"># stack.yaml</span>
   <span class="fu">resolver:</span> lts-2.15</code></pre></div>
<ul>
<li>LTS resolver versions imply a version of GHC
<ul>
<li>the 2.x series implies GHC 7.8</li>
<li>the upcoming 3.x series implies GHC 7.10</li>
</ul></li>
<li>Running <code>stack build</code> examines your cabal file and generates a stack.yaml that fits</li>
<li>Stack can share dependencies between projects
<ul>
<li>it improves the cabal sandboxing state of the art</li>
<li>avoids reinstalling things for every project</li>
</ul></li>
<li>You can supplement LTS snapshots
<ul>
<li>with newer package versions on package</li>
<li>patched version on the disk</li>
<li>or straight from a github repo</li>
</ul></li>
<li>Stackage projects can contain multiple packages
<ul>
<li>Example of how Yesod uses multiple packages</li>
</ul></li>
<li>Discussion of custom scripts in builds</li>
<li>Stack reimplements the features of cabal-install, and uses the cabal library underneath</li>
<li>Stack prefers to use a GHC found on your path but will suggest <code>stack setup</code> if the version does not match the resolver
<ul>
<li>it will also install other tools as needed like alex, happy and cpphs</li>
</ul></li>
<li>Q&amp;A</li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Thinking with Laziness</title>
    <link href="http://begriffs.com/posts/2015-06-17-thinking-with-laziness.html" />
    <id>http://begriffs.com/posts/2015-06-17-thinking-with-laziness.html</id>
    <published>2015-06-17T00:00:00Z</published>
    <updated>2015-06-17T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post-header">
  <h3>Thinking with Laziness</h3>
  <a href="https://twitter.com/share" class="twitter-share-button pull-right"
     data-via="begriffs" data-count="none">Tweet</a>
  <h5 class="text-muted">June 17, 2015</h5>
</div>

<div class="content">
  <p><a href="http://jelv.is/">Tikhon Jelvis</a> gave this talk at <a href="http://bayhac.org/">Bayhac 2015</a>. He describes how lazy evaluation supports deeper kinds of program modularity and suggests we embrace it for what it really is. [<a href="http://jelv.is/talks/thinking-with-laziness/#slide1">slides</a>]</p>
<video poster="https://i.vimeocdn.com/video/522904112.jpg?mw=700" class="video-js vjs-default-skin" controls preload="auto">
<source src="https://player.vimeo.com/external/130846004.hd.mp4?s=86274ac953fba73bbb7ecad0359a298d" type="video/mp4">
</video>
<h3 id="summary">Summary</h3>
<ul>
<li>Stop thinking of Haskell like a strict language which happens to be lazy</li>
<li>Laziness ia a new sort of modularity that we’re not used to from other languages</li>
<li>It separates the definition of something from how it gets evaluated</li>
<li>It lets us think of control flow the way we would think of data structures</li>
<li>Deal with arbitrary precision (like vector graphics vs raster graphics)</li>
<li>Shortcuts for free — <code>take 5 $ sort xs</code> actually stops the sorting after five elements are found. No break statement needed inside the sort function.</li>
<li>Another example: alpha beta pruning game trees. We can use a simple tree structure and just choose not to evaluate branches and that does pruning.</li>
<li>In Haskell lists stand in for loops. Control flow can be manipulated as data.</li>
<li>Lazy structures don’t necessarily need to fully exist in memory.</li>
<li>Convenient nondeterministic programming
<ul>
<li>variables can take many combinations of values from which we can later choose</li>
<li>map coloring example</li>
</ul></li>
<li>Lazy data structures is like precision on demand
<ul>
<li>it’s like the advantage of vector graphics over raster</li>
<li>exact real arithmetic</li>
<li>infinite quadtrees</li>
</ul></li>
<li>Laziness allows memoization below the level of abstraction
<ul>
<li>we can rely on it without having to do it ourselves</li>
<li>similar to garbage collection in this way, improves modularity</li>
</ul></li>
<li>Some people mistakenly believe Haskell does memoization automatically everywhere
<ul>
<li>that’s actually not feasible but there are packages to help: <a href="https://hackage.haskell.org/package/data-memocombinators">data-memocombinators</a> and <a href="https://hackage.haskell.org/package/MemoTrie">MemoTrie</a></li>
</ul></li>
<li>Dynamic programming
<ul>
<li>no need to initialize everything or worry about reading one subproblem too early</li>
<li>just declare your array as containing all subproblems and the fact that it’s lazy ensures everything is evaluated in the correct order and at most once</li>
</ul></li>
<li>We saw four perspectives that turned out to be interrelated: modularity, control, precision, and memorization</li>
<li>Q&amp;A</li>
</ul>
</div>
]]></summary>
</entry>

</feed>
